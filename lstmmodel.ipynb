{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jQtITYvXR5bpQ6VAbB6ZH8dgHwbAx5dG",
      "authorship_tag": "ABX9TyNbKaZWt5y2WUngCZ8ToTvJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras --quiet\n",
        "!pip install tensorflow --quiet"
      ],
      "metadata": {
        "id": "8ZGfwgFUjrFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuxI8Ws2_ydU",
        "outputId": "09593a41-66c5-450a-d0f1-91dc57d060a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbRd8630fcm5",
        "outputId": "fff8eece-1c3d-4ddd-ea27-0fa6c9347120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from gensim.models import FastText\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('arxiv_data.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvgM15ICjIAX",
        "outputId": "f702b501-16c8-41fa-9244-f59729f2ec47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51774 entries, 0 to 51773\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   titles     51774 non-null  object\n",
            " 1   summaries  51774 non-null  object\n",
            " 2   terms      51774 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['terms'],inplace =True, axis=1)"
      ],
      "metadata": {
        "id": "rTu8X7fijJBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0KKnYmAjSnD",
        "outputId": "0ce1a3fa-5774-402c-e7d9-c113bb5ac6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.iloc[:1000, :]\n"
      ],
      "metadata": {
        "id": "9C6V-Y4KIbxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tiJUfgsz446S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['titles']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-Erzt4RfhnY",
        "outputId": "80103374-9858-495c-ee8d-5477f0347396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      survey on semantic stereo matching semantic de...\n",
              "1      futureai guiding principles and consensus reco...\n",
              "2      enforcing mutual consistency of hard regions f...\n",
              "3      parameter decoupling strategy for semisupervis...\n",
              "4      backgroundforeground segmentation for interior...\n",
              "                             ...                        \n",
              "995    deepigeos a deep interactive geodesic framewor...\n",
              "996    d densely convolutional networks for volumetri...\n",
              "997    uinet interactive artificial neural networks f...\n",
              "998           oneshot learning for semantic segmentation\n",
              "999    exploring and exploiting diversity for image s...\n",
              "Name: titles, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['titles'] = df['titles'].apply(preprocess_text)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['titles'])\n",
        "sequences = tokenizer.texts_to_sequences(df['titles'])\n",
        "max_len = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# Create input and target sequences\n",
        "input_sequences = padded_sequences[:,:-1]\n",
        "target_sequences = padded_sequences[:,1:]"
      ],
      "metadata": {
        "id": "IMrTOeRRU7zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfrm43yHWPRx",
        "outputId": "06cf80b2-ed19-4c22-a823-93b892425779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  99,   21,   13, ...,    0,    0,    0],\n",
              "       [ 828,  829,  830, ...,    0,    0,    0],\n",
              "       [ 509,  219,  143, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [2269,   38,  342, ...,    0,    0,    0],\n",
              "       [ 319,    5,    2, ...,    0,    0,    0],\n",
              "       [ 826,    4,  477, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def add_end_token(text):\n",
        "    # Add end token after every sentence\n",
        "    text = re.sub(r'([^.]*\\.)', r'\\1 <end>', text)\n",
        "    # Remove trailing spaces and <end> tokens\n",
        "    text = text.strip().replace(' <end>', '<end>')\n",
        "    # Add <end> token if missing\n",
        "    if not text.endswith('<end>'):\n",
        "        text += ' <end>'\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "df['titles'] = df['titles'].apply(add_end_token)\n"
      ],
      "metadata": {
        "id": "1kwdOghsBLr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# define the input and output data\n",
        "data = df['titles']\n",
        "\n",
        "# tokenize the data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "# prepare the input and output data\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "input_data = []\n",
        "output_data = []\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        input_seq = sequence[:i]\n",
        "        input_seq = pad_sequences([input_seq], maxlen=max_sequence_length)[0]\n",
        "        output_seq = to_categorical(sequence[i], num_classes=len(tokenizer.word_index) + 1)\n",
        "        input_data.append(input_seq)\n",
        "        output_data.append(output_seq)\n",
        "input_data = np.array(input_data)\n",
        "output_data = np.array(output_data)\n",
        "\n",
        "fasttext = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/wiki-news-300d-1M.vec')\n",
        "\n",
        "# create an embedding matrix for the words in our vocabulary\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in fasttext:\n",
        "        embedding_matrix[i] = fasttext[word]\n",
        "\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, weights=[embedding_matrix], trainable=True))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XzpVxmUyWRjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(input_data, output_data, initial_epoch=100, epochs=200)"
      ],
      "metadata": {
        "id": "DyYhEE8_tOJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test_data = df['titles'][0:500]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "test_input = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "test_output = model.predict(test_input)\n",
        "\n",
        "# Evaluate the performance of the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_input, test_output)\n",
        "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YITpBvv5aoCQ",
        "outputId": "319a53af-b4bd-4aef-dced-75337151230e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 2s 88ms/step\n",
            "16/16 [==============================] - 2s 56ms/step - loss: 0.5311 - accuracy: 1.0000\n",
            "Test loss: 0.5311, Test accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "model.save('lstm_model_4.h5')\n",
        "files.download(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wXcqOVzS9fEu",
        "outputId": "29175f36-1e85-4f88-fd45-407b3507f666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d0e6c50-6141-40d8-bd7c-e13d15926873\", \"lstm_model_4.h5\", 20946336)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from tensorflow.keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"lstm_model_4.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Download JSON file\n",
        "files.download(\"lstm_model_4.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OxlBcMJyezUs",
        "outputId": "2dc34d5c-b5e4-4026-bc11-b1e5092d7de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_565e8be4-74ff-4ae5-837a-0f9aeb28bacd\", \"lstm_model_4.json\", 2957)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "\n",
        "with open('/content/lstm_tokenizer.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "    tokenizer_json = json.dumps(data)  # Convert dictionary to JSON-formatted string\n",
        "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
        "\n",
        "model = tf.keras.models.load_model('/content/lstm_model_4.h5')\n"
      ],
      "metadata": {
        "id": "cJ08jS2V98VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, input_text, max_length=20):\n",
        "    # initialize the generated output text with the input text\n",
        "    generated_text = input_text\n",
        "    # set the stop condition to False\n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "        # tokenize the input text\n",
        "        input_sequence = tokenizer.texts_to_sequences([generated_text])[0]\n",
        "        # pad the input sequence\n",
        "        input_sequence = pad_sequences([input_sequence], maxlen=max_length-1, padding='pre')\n",
        "        # make a prediction\n",
        "        prediction = model.predict(input_sequence)[0]\n",
        "        # get the index of the predicted word\n",
        "        predicted_index = np.argmax(prediction)\n",
        "        # get the predicted word\n",
        "        predicted_word = tokenizer.index_word.get(predicted_index, '')\n",
        "        # check if we've generated the maximum length or found the end token\n",
        "        if len(generated_text.split()) == max_length or predicted_word == 'end':\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            # append the predicted word to the generated text\n",
        "            generated_text += ' ' + predicted_word\n",
        "    return generated_text.strip()\n"
      ],
      "metadata": {
        "id": "aq7q4_SPXSJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'ensemble learning based'\n",
        "generated_text = generate_text(model, tokenizer, input_text)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwMuM1TIabCJ",
        "outputId": "75aa9303-23fa-489b-af99-b0a86337d966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "ensemble learning based on classifier prediction confidence and comprehensive learning particle swarm optimisation for polyp localisation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gpORJ52yARmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}